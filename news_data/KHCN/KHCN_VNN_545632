Theo The Verge , ứng dụng này có tên là DeepNude và nó là ví dụ mới nhất về việc lạm dụng AI để tạo ra ứng dụng tệ hại. Phần mềm này dược phát hiện đầu tiên bởi Samantha Cole của Motherboard. Nó có sẵn và cho phép tải xuống miễn phí trên Windows. Với phiên bản cao cấp sẽ cho những bức ảnh đầu ra có độ phân giải cao hơn với việc người dùng phải trả phí 99 USD. Tuy nhiên, ở cả 2 phiên bản miễn phí và cao cấp, hình ảnh khỏa thân được tạo ra bởi AI đều có xác nhận "Fake nude" để cảnh báo đây là hình ảnh giả mạo. Với các bức ảnh khỏa thân giả mạo được AI tạo ra, nếu lướt qua người xem sẽ lầm tưởng rằng đây là ảnh thật. Nhưng khi xem kỹ, họ sẽ nhận ra đây là những bức ảnh được làm giả với phần da bị mờ. Ngoài ra, ứng dụng này cũng chỉ thực hiện được tốt nhất với các hình ảnh có độ phân giải cao và người trong hình mặc bikini hoặc quá hở hang. Tuy nhiên, những bức ảnh được tạo ra bởi ứng dụng này cũng rất dễ bị nhầm lẫn với ảnh thật và có thể gây ra những "tổn thất" không hề nhỏ cho ai đó bị kẻ xấu lạm dụng. Chúng có thể tạo ra hình ảnh giả mạo để quấy rối, đe dọa hay thậm chí trả thù ai đó... chỉ trong vài giây. Người tạo ra ứng dụng DeepNude này, tự nhận là Alberto, cho biết, anh ta tạo ra nó để gợi nhớ về những ký ức của tuổi thơ với các cuốn truyện tranh có nhân vật sở hữu khả năng siêu nhiên là nhìn xuyên thấu. Alberto cũng nói thêm rằng, DeepNude được tạo ra với mục đích giải trí chứ không mong đợi nó trở nên phổ biến. Dẫu sao, DeepNude là một ứng dụng xấu và nó đang gặp phải sự phản đối gay gắt của nhiều người trên các diễn đàn mạng. Còn các luật sư nói rằng, ảnh khoả thân do AI tạo ra có thể cấu thành tội phỉ báng. Hải Phong (theo The Verge)