Theo , công nghệ nhận dạng giọng nói do nhóm 5 công ty trên phát triển mắc lỗi nhiều gấp đôi khi Mỹ gốc Phi (người Mỹ da đen) so với giọng Mỹ (da trắng). Đây là công bố từ kết quả nghiên cứu đăng trên (Kỷ yếu Viện hàn lâm Khoa học Quốc gia Mỹ), tạp chí khoa học đa ngành chính thức của Viện hàn lâm Khoa học Quốc gia Mỹ. Cả 5 hệ thống nhận dạng giọng nói đều mắc tỷ lệ lỗi cao dù đối tượng thử nghiệm cùng độ tuổi, giới tính và nói những từ giống hệt nhau. Hiện chưa rõ liệu công nghệ từ 5 “gã khổng lồ” trên có sử dụng trên các trợ lý ảo như Siri hay Alexa hay không và không đơn vị nào trong số này cung cấp thêm thông tin. Nếu có, các sản phẩm này sẽ cung cấp thứ dịch vụ tồi tệ trên diện rộng cho lượng khách hàng khổng lồ, có thể gây tác động lớn tới hằng ngày của họ. Nhận dạng giọng nói hiện sử dụng trong phán quyết nhập cư, quyết định tuyển dụng và cáo trạng tòa án. Công nghệ này cũng rất quan trọng đối với những người không thể dùng tay để sử dụng máy tính. Và với đà phát triển rộng và nhanh chóng trong những năm tới, bất kỳ sự thiên vị chủng tộc nào cũng có thể gây ra hậu quả nghiêm trọng tới sự nghiệp, đời sống. Để đi đến kết luận “phân biệt chủng tộc”, các nhà nghiên cứu đã thử nghiệm công nghệ của từng công ty với hơn 2.000 mẫu giọng từ các cuộc phỏng vấn được ghi âm lại giữa người Mỹ gốc Phi và người Mỹ da trắng. Trung bình, hệ thống nghe nhầm 35% số từ do người Mỹ gốc Phi nói, trong khi với nhóm còn lại chỉ 19%. Tỷ lệ lỗi cao nhất rơi vào nhóm đàn ông Mỹ gốc Phi, nhất là khi họ sử dụng nhiều tiếng bản địa. Sự sai sót này dường như là hệ quả của một vấn đề rất phổ biến với AI: trí tuệ nhân tạo đang dựa vào dữ liệu được người da trắng cung cấp. Sharad Goel, Giáo sư ngành Kỹ thuật tính toán tại Đại học Standford (Mỹ) đã giám sát cuộc nghiên cứu và tin rằng phát hiện này cho thấy cần phải kiểm toán độc lập . “Chúng ta không thể tin tưởng để các công ty tự điều chỉnh sản phẩm của họ”, bà nói.